"""CryptoScanner News Explorer ‚Äî —Ç–µ—Å—Ç 4 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ + AI."""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import json
import os
from datetime import datetime

from tabulate import tabulate

import config
from database import db
from services.news_cryptocv import CryptoCVClient
from services.news_cryptopanic import CryptoPanicClient
from services.news_binance import BinanceAnnouncementsClient
from services.news_google import GoogleNewsClient
from services.event_extractor import EventExtractor


# ---------------------------------------------------------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ
# ---------------------------------------------------------------------------

def _detect_fields(items: list) -> list[list[str]]:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—è –∏ —Ç–∏–ø—ã –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞."""
    if not items or not isinstance(items[0], dict):
        return []
    first = items[0]
    rows: list[list[str]] = []
    for key, val in first.items():
        type_name = type(val).__name__
        example = str(val)[:50]
        rows.append([key, type_name, example])
    return rows


def _raw_json(data: list, limit: int = 2) -> str:
    """JSON –ø–µ—Ä–≤—ã—Ö N —ç–ª–µ–º–µ–Ω—Ç–æ–≤."""
    return json.dumps(data[:limit], indent=2, ensure_ascii=False, default=str)


def _news_to_raw_news(
    items: list[dict], source: str, extractor_fn: callable
) -> list[dict]:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç raw_news."""
    result: list[dict] = []
    for item in items:
        result.append(extractor_fn(item, source))
    return result


# ---------------------------------------------------------------------------
# –®–∞–≥ 1: –í–∞–ª–∏–¥–∞—Ü–∏—è
# ---------------------------------------------------------------------------

def step_validate() -> dict[str, bool]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–π."""
    print("\n‚öôÔ∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    status: dict[str, bool] = {}

    if config.CRYPTOPANIC_TOKEN:
        print("   CRYPTOPANIC_TOKEN:  ‚úÖ –∑–∞–¥–∞–Ω")
        status["cryptopanic"] = True
    else:
        print("   CRYPTOPANIC_TOKEN:  ‚ö†Ô∏è –Ω–µ –∑–∞–¥–∞–Ω (–ø—Ä–æ–ø—É—â—É CryptoPanic)")
        status["cryptopanic"] = False

    if config.GROQ_API_KEY:
        print("   GROQ_API_KEY:       ‚úÖ –∑–∞–¥–∞–Ω")
        status["groq"] = True
    else:
        print("   GROQ_API_KEY:       ‚ö†Ô∏è –Ω–µ –∑–∞–¥–∞–Ω (–ø—Ä–æ–ø—É—â—É AI-–ø–∞—Ä—Å–∏–Ω–≥)")
        status["groq"] = False

    print("   cryptocurrency.cv:  ‚úÖ (–∫–ª—é—á –Ω–µ –Ω—É–∂–µ–Ω)")
    status["cryptocv"] = True
    print("   Binance:            ‚úÖ (–∫–ª—é—á –Ω–µ –Ω—É–∂–µ–Ω)")
    status["binance"] = True
    print("   Google News RSS:    ‚úÖ (–∫–ª—é—á –Ω–µ –Ω—É–∂–µ–Ω)")
    status["google"] = True

    return status


# ---------------------------------------------------------------------------
# –®–∞–≥ 3A: cryptocurrency.cv
# ---------------------------------------------------------------------------

def explore_cryptocv(report: dict) -> list[dict]:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ cryptocurrency.cv. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw_news items."""
    print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CRYPTOCURRENCY.CV ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    client = CryptoCVClient(
        base_url=config.CRYPTOCV_NEWS_URL,
        timeout=config.REQUEST_TIMEOUT,
        delay=config.CRYPTOCV_DELAY,
    )

    print("üîå –ü—Ä–æ–≤–µ—Ä—è—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
    if not client.check_connection():
        print("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")
        report["sources"]["cryptocv"] = {"status": "error", "count": 0}
        return []
    print("‚úÖ OK")

    print("\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏...")
    raw_items = client.get_latest_news(limit=50)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(raw_items)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    if raw_items:
        print(f"\nüì∞ RAW (–ø–µ—Ä–≤—ã–µ 2):")
        print(_raw_json(raw_items))

        fields = _detect_fields(raw_items)
        if fields:
            print(f"\nüì∞ –ü–æ–ª—è:")
            print(tabulate(fields, headers=["–ü–æ–ª–µ", "–¢–∏–ø", "–ü—Ä–∏–º–µ—Ä"],
                           tablefmt="simple_outline"))

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ raw_news —Ñ–æ—Ä–º–∞—Ç
    news_items = [_convert_cryptocv(item) for item in raw_items]
    saved = db.upsert_raw_news(news_items)
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ raw_news: {saved} –Ω–æ–≤—ã—Ö")

    report["sources"]["cryptocv"] = {"status": "ok", "count": len(raw_items), "saved": saved}
    return news_items


def _convert_cryptocv(item: dict) -> dict:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è cryptocurrency.cv —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç raw_news."""
    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞ ‚Äî –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è
    title = (item.get("title") or item.get("headline") or
             item.get("name") or str(item)[:200])
    url = item.get("url") or item.get("link") or ""
    published = item.get("published_at") or item.get("date") or item.get("created_at")
    tickers_raw = item.get("tickers") or item.get("currencies") or item.get("symbols")
    if isinstance(tickers_raw, list):
        tickers = ",".join(str(t) for t in tickers_raw)
    elif isinstance(tickers_raw, str):
        tickers = tickers_raw
    else:
        tickers = ""
    domain = item.get("domain") or item.get("source") or "cryptocurrency.cv"
    if isinstance(domain, dict):
        domain = domain.get("domain", domain.get("name", "cryptocurrency.cv"))

    return {
        "source": "cryptocv",
        "title": str(title),
        "url": str(url),
        "published_at": str(published) if published else None,
        "tickers": tickers,
        "domain": str(domain),
        "sentiment": None,
        "votes_positive": 0,
        "votes_important": 0,
        "raw_json": item,
    }


# ---------------------------------------------------------------------------
# –®–∞–≥ 3B: CryptoPanic
# ---------------------------------------------------------------------------

def explore_cryptopanic(report: dict) -> list[dict]:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ CryptoPanic. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw_news items."""
    print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CRYPTOPANIC ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    client = CryptoPanicClient(
        auth_token=config.CRYPTOPANIC_TOKEN,
        base_url=config.CRYPTOPANIC_BASE_URL,
        timeout=config.REQUEST_TIMEOUT,
        delay=config.CRYPTOPANIC_DELAY,
    )

    print("üîå –ü—Ä–æ–≤–µ—Ä—è—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
    if not client.check_connection():
        print("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")
        report["sources"]["cryptopanic"] = {"status": "error", "count": 0}
        return []
    print("‚úÖ OK")

    # –í–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    print("\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (filter=important)...")
    important = client.get_important_news(limit=30)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(important)} –≤–∞–∂–Ω—ã—Ö")

    # –í—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ
    print("\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ...")
    latest = client.get_latest_news(limit=50)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(latest)} –ø–æ—Å–ª–µ–¥–Ω–∏—Ö")

    if latest:
        print(f"\nüì∞ RAW (–ø–µ—Ä–≤—ã–µ 2):")
        print(_raw_json(latest))

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ title)
    seen_titles: set[str] = set()
    all_items: list[dict] = []
    for item in important + latest:
        t = item.get("title", "")
        if t not in seen_titles:
            seen_titles.add(t)
            all_items.append(item)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    news_items = [_convert_cryptopanic(item) for item in all_items]
    saved = db.upsert_raw_news(news_items)
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ raw_news: {saved} –Ω–æ–≤—ã—Ö")

    report["sources"]["cryptopanic"] = {
        "status": "ok", "count": len(all_items),
        "important": len(important), "saved": saved,
    }
    return news_items


def _convert_cryptopanic(item: dict) -> dict:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CryptoPanic –ø–æ—Å—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç raw_news."""
    tickers = CryptoPanicClient.extract_tickers(item)
    votes = item.get("votes", {})
    source_info = item.get("source", {})
    domain = source_info.get("domain", "") if isinstance(source_info, dict) else ""

    return {
        "source": "cryptopanic",
        "title": item.get("title", ""),
        "url": item.get("url", ""),
        "published_at": item.get("published_at"),
        "tickers": ",".join(tickers),
        "domain": domain,
        "sentiment": None,
        "votes_positive": votes.get("positive", 0) if isinstance(votes, dict) else 0,
        "votes_important": votes.get("important", 0) if isinstance(votes, dict) else 0,
        "raw_json": item,
    }


# ---------------------------------------------------------------------------
# –®–∞–≥ 3C: Binance Announcements
# ---------------------------------------------------------------------------

def explore_binance(report: dict) -> list[dict]:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ Binance Announcements. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw_news items."""
    print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê BINANCE ANNOUNCEMENTS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    client = BinanceAnnouncementsClient(
        timeout=config.REQUEST_TIMEOUT,
        delay=config.BINANCE_DELAY,
    )

    print("üîå –ü—Ä–æ–≤–µ—Ä—è—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
    if not client.check_connection():
        print("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å (POST –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω)")
        report["sources"]["binance"] = {"status": "error", "count": 0}
        return []
    print("‚úÖ OK")

    all_articles: list[dict] = []

    # –õ–∏—Å—Ç–∏–Ω–≥–∏
    print("\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –ª–∏—Å—Ç–∏–Ω–≥–∏ (catalogId=48)...")
    listings = client.get_listings(page_size=20)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(listings)}")
    all_articles.extend(listings)

    # –î–µ–ª–∏—Å—Ç–∏–Ω–≥–∏
    print("\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –¥–µ–ª–∏—Å—Ç–∏–Ω–≥–∏ (catalogId=131)...")
    delistings = client.get_delistings(page_size=20)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(delistings)}")
    all_articles.extend(delistings)

    if all_articles:
        print(f"\nüì∞ RAW (–ø–µ—Ä–≤—ã–µ 2):")
        print(_raw_json(all_articles))

        fields = _detect_fields(all_articles)
        if fields:
            print(f"\nüì∞ –ü–æ–ª—è:")
            print(tabulate(fields, headers=["–ü–æ–ª–µ", "–¢–∏–ø", "–ü—Ä–∏–º–µ—Ä"],
                           tablefmt="simple_outline"))

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    news_items = [_convert_binance(item) for item in all_articles]
    saved = db.upsert_raw_news(news_items)
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ raw_news: {saved} –Ω–æ–≤—ã—Ö")

    report["sources"]["binance"] = {
        "status": "ok", "count": len(all_articles),
        "listings": len(listings), "delistings": len(delistings), "saved": saved,
    }
    return news_items


def _convert_binance(item: dict) -> dict:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Binance article –≤ —Ñ–æ—Ä–º–∞—Ç raw_news."""
    title = item.get("title") or item.get("name") or str(item)[:200]
    code = item.get("code", "")
    url = f"https://www.binance.com/en/support/announcement/{code}" if code else ""
    release_date = item.get("releaseDate") or item.get("publishDate")
    if isinstance(release_date, (int, float)) and release_date > 1e12:
        # Binance –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å timestamp –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        from datetime import datetime as dt
        release_date = dt.fromtimestamp(release_date / 1000).isoformat()

    return {
        "source": "binance",
        "title": str(title),
        "url": url,
        "published_at": str(release_date) if release_date else None,
        "tickers": "",
        "domain": "binance.com",
        "sentiment": None,
        "votes_positive": 0,
        "votes_important": 0,
        "raw_json": item,
    }


# ---------------------------------------------------------------------------
# –®–∞–≥ 3D: Google News RSS
# ---------------------------------------------------------------------------

def explore_google_news(report: dict) -> list[dict]:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ Google News RSS. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw_news items."""
    print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê GOOGLE NEWS RSS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    client = GoogleNewsClient(
        base_url=config.GOOGLE_NEWS_RSS_BASE,
        delay=config.GOOGLE_NEWS_DELAY,
        max_total=config.MAX_GOOGLE_NEWS_TOTAL,
    )

    print("üîå –ü—Ä–æ–≤–µ—Ä—è—é –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
    if not client.check_connection():
        print("‚ùå Google News RSS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        report["sources"]["google"] = {"status": "error", "count": 0}
        return []
    print("‚úÖ OK")

    print(f"\nüì∞ –ó–∞–≥—Ä—É–∂–∞—é –Ω–æ–≤–æ—Å—Ç–∏ ({len(config.GOOGLE_NEWS_QUERIES)} –∑–∞–ø—Ä–æ—Å–æ–≤)...")
    for q in config.GOOGLE_NEWS_QUERIES:
        print(f"   ‚Ä¢ {q}")

    all_entries = client.fetch_all(config.GOOGLE_NEWS_QUERIES)
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ: {len(all_entries)} –Ω–æ–≤–æ—Å—Ç–µ–π (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ title)")

    if all_entries:
        print(f"\nüì∞ RAW (–ø–µ—Ä–≤—ã–µ 2):")
        print(_raw_json(all_entries))

        fields = _detect_fields(all_entries)
        if fields:
            print(f"\nüì∞ –ü–æ–ª—è:")
            print(tabulate(fields, headers=["–ü–æ–ª–µ", "–¢–∏–ø", "–ü—Ä–∏–º–µ—Ä"],
                           tablefmt="simple_outline"))

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ raw_news —Ñ–æ—Ä–º–∞—Ç
    news_items = [_convert_google(entry) for entry in all_entries]
    saved = db.upsert_raw_news(news_items)
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ raw_news: {saved} –Ω–æ–≤—ã—Ö")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º
    from collections import Counter
    query_counter: Counter[str] = Counter(e["query"] for e in all_entries)
    if query_counter:
        print(f"\nüìä –ü–æ –∑–∞–ø—Ä–æ—Å–∞–º:")
        q_tbl = [[q, cnt] for q, cnt in query_counter.most_common()]
        print(tabulate(q_tbl, headers=["–ó–∞–ø—Ä–æ—Å", "–ö–æ–ª-–≤–æ"],
                       tablefmt="simple_outline"))

    report["sources"]["google"] = {
        "status": "ok",
        "count": len(all_entries),
        "queries": len(config.GOOGLE_NEWS_QUERIES),
        "saved": saved,
    }
    return news_items


def _convert_google(entry: dict) -> dict:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Google News RSS entry –≤ —Ñ–æ—Ä–º–∞—Ç raw_news."""
    title = entry.get("title", "")
    url = entry.get("link", "")
    published = GoogleNewsClient.parse_published(entry)
    source_name = entry.get("source_name", "Google News")

    return {
        "source": "google_news",
        "title": str(title),
        "url": str(url),
        "published_at": published,
        "tickers": "",
        "domain": str(source_name),
        "sentiment": None,
        "votes_positive": 0,
        "votes_important": 0,
        "raw_json": entry,
    }


# ---------------------------------------------------------------------------
# –®–∞–≥ 4: AI Event Extraction
# ---------------------------------------------------------------------------

def explore_ai_extraction(report: dict) -> None:
    """AI-–ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Groq."""
    print("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê AI EVENT EXTRACTION ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    extractor = EventExtractor(
        api_key=config.GROQ_API_KEY,
        api_url=config.GROQ_API_URL,
        model=config.GROQ_MODEL,
        delay=config.GROQ_DELAY,
        timeout=30,
    )

    print("üîå –ü—Ä–æ–≤–µ—Ä—è—é Groq API...")
    if not extractor.check_connection():
        print("‚ùå Groq API –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
        report["ai"] = {"status": "error"}
        return
    print(f"‚úÖ Groq OK (–º–æ–¥–µ–ª—å: {config.GROQ_MODEL})")

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
    print("\nü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –Ω–µ–ø—Ä–æ—Ü–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏...")
    unprocessed = db.get_unprocessed_news(limit=100)
    print(f"   –ù–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(unprocessed)}")

    if not unprocessed:
        print("   –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        report["ai"] = {"status": "ok", "processed": 0, "events": 0}
        return

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è AI
    news_for_ai: list[dict] = []
    news_ids: list[int] = []
    for n in unprocessed:
        tickers = n.get("tickers", "")
        ticker_list = [t.strip() for t in tickers.split(",") if t.strip()]
        news_for_ai.append({
            "title": n["title"],
            "url": n.get("url", ""),
            "source": n.get("domain", n.get("source", "")),
            "domain": n.get("domain", ""),
            "published_at": n.get("published_at", ""),
            "tickers": ticker_list,
        })
        news_ids.append(n["id"])

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π
    extracted = extractor.extract_events(news_for_ai)

    # –ü–æ–º–µ—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
    db.mark_news_processed(news_ids)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ events –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    events_to_save: list[dict] = []
    for ev in extracted:
        ni = ev.get("news_index")
        news_id = news_ids[ni] if ni is not None and ni < len(news_ids) else None
        events_to_save.append({
            "caption": ev["title"],
            "source": ev.get("source_url", ""),
            "source_type": "ai_parsed",
            "source_reliable": 0,
            "important": 1 if ev.get("importance") == "high" else 0,
            "date_public": datetime.now().strftime("%Y-%m-%d"),
            "date_start": ev.get("date_event") or datetime.now().strftime("%Y-%m-%d"),
            "coin_symbol": ev.get("coin_symbol"),
            "event_type": ev.get("event_type"),
            "importance": ev.get("importance", "medium"),
            "news_id": news_id,
        })

    saved = db.upsert_events(events_to_save)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    from collections import Counter
    type_counter: Counter[str] = Counter(ev.get("event_type", "other") for ev in extracted)
    coin_counter: Counter[str] = Counter(ev.get("coin_symbol", "?") for ev in extracted)

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç AI-–ø–∞—Ä—Å–∏–Ω–≥–∞:")
    print(f"   –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(unprocessed)}")
    print(f"   –°–æ–±—ã—Ç–∏–π –∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(extracted)}")
    print(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ (–º—É—Å–æ—Ä): {len(unprocessed) - len(extracted)}")

    if type_counter:
        print(f"\n   –ü–æ —Ç–∏–ø–∞–º:")
        type_tbl = [[et, cnt] for et, cnt in type_counter.most_common()]
        print(tabulate(type_tbl, headers=["–¢–∏–ø", "–ö–æ–ª-–≤–æ"], tablefmt="simple_outline"))

    if coin_counter:
        print(f"\n   –ü–æ –º–æ–Ω–µ—Ç–∞–º:")
        coin_tbl = [
            [sym, cnt, "‚úÖ" if sym in config.BINANCE_SYMBOLS else ""]
            for sym, cnt in coin_counter.most_common(10)
        ]
        print(tabulate(coin_tbl, headers=["–°–∏–º–≤–æ–ª", "–ö–æ–ª-–≤–æ", "Binance?"],
                       tablefmt="simple_outline"))

    # –ü—Ä–∏–º–µ—Ä—ã
    if extracted:
        print(f"\nüìÖ –ü–†–ò–ú–ï–†–´ –ò–ó–í–õ–ï–ß–Å–ù–ù–´–• –°–û–ë–´–¢–ò–ô:")
        for i, ev in enumerate(extracted[:5], 1):
            et = ev.get("event_type", "?")
            imp = ev.get("importance", "?")[:3].upper()
            sym = ev.get("coin_symbol", "?")
            title = ev.get("title", "?")[:60]
            date = ev.get("date_event") or "?"
            print(f"   {i}. [{et}] [{imp}] {sym} ‚Äî \"{title}\" ‚Äî {date}")

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ events: {saved} –Ω–æ–≤—ã—Ö")

    binance_events = sum(1 for ev in extracted if ev.get("coin_symbol") in config.BINANCE_SYMBOLS)
    report["ai"] = {
        "status": "ok",
        "processed": len(unprocessed),
        "events": len(extracted),
        "saved": saved,
        "binance_events": binance_events,
        "by_type": dict(type_counter),
    }


# ---------------------------------------------------------------------------
# –®–∞–≥ 5: –°–≤–æ–¥–Ω—ã–π –æ—Ç—á—ë—Ç
# ---------------------------------------------------------------------------

def build_summary(report: dict) -> str:
    """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞."""
    lines: list[str] = []

    lines.append("‚ïê" * 63)
    lines.append("         CRYPTOSCANNER ‚Äî NEWS & EVENTS EXPLORATION")
    lines.append(f"         {report['date']}")
    lines.append("‚ïê" * 63)

    # –¢–∞–±–ª–∏—Ü–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    lines.append("\nüì° –ò–°–¢–û–ß–ù–ò–ö–ò –ù–û–í–û–°–¢–ï–ô")
    src_table: list[list[str]] = []
    for src_key, label in [
        ("cryptocv", "cryptocurrency.cv"),
        ("cryptopanic", "CryptoPanic"),
        ("binance", "Binance Announce"),
        ("google", "Google News RSS"),
        ("coindar", "Coindar"),
    ]:
        info = report["sources"].get(src_key, {})
        st = info.get("status", "skip")
        status_str = "‚úÖ OK" if st == "ok" else ("‚ùå ERR" if st == "error" else "‚è≥ SKIP")
        count = info.get("count", "-")
        note = info.get("note", "")
        if src_key == "coindar":
            note = "–ñ–¥—ë–º –∫–ª—é—á"
        elif src_key == "cryptocv":
            note = "–ë–µ–∑ –∫–ª—é—á–∞"
        elif src_key == "cryptopanic" and st == "ok":
            note = f"important={info.get('important', '?')}"
        elif src_key == "binance" and st == "ok":
            note = f"listings={info.get('listings', 0)}+delist={info.get('delistings', 0)}"
        elif src_key == "google" and st == "ok":
            note = f"queries={info.get('queries', 0)}"
        src_table.append([label, status_str, str(count), note])

    lines.append(tabulate(
        src_table, headers=["–ò—Å—Ç–æ—á–Ω–∏–∫", "–°—Ç–∞—Ç—É—Å", "–ù–æ–≤–æ—Å—Ç–µ–π", "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ"],
        tablefmt="simple_outline",
    ))

    # AI
    ai = report.get("ai", {})
    if ai.get("status") == "ok":
        lines.append(f"\nü§ñ AI –ü–ê–†–°–ò–ù–ì (Groq)")
        lines.append(f"   –ù–æ–≤–æ—Å—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:    {ai.get('processed', 0)}")
        lines.append(f"   –°–æ–±—ã—Ç–∏–π –∏–∑–≤–ª–µ—á–µ–Ω–æ:       {ai.get('events', 0)}")
        binance_ev = ai.get("binance_events", 0)
        lines.append(f"   –ò–∑ –Ω–∏—Ö –ø–æ Binance:       {binance_ev}")

        by_type = ai.get("by_type", {})
        if by_type:
            lines.append(f"\nüìä –°–û–ë–´–¢–ò–Ø –ü–û –¢–ò–ü–ê–ú")
            type_tbl = [[et, cnt] for et, cnt in
                        sorted(by_type.items(), key=lambda x: -x[1])]
            lines.append(tabulate(type_tbl, headers=["–¢–∏–ø", "–ö–æ–ª-–≤–æ"],
                                  tablefmt="simple_outline"))
    elif ai.get("status") == "error":
        lines.append(f"\nü§ñ AI –ü–ê–†–°–ò–ù–ì: ‚ùå Groq –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    else:
        lines.append(f"\nü§ñ AI –ü–ê–†–°–ò–ù–ì: ‚è≥ GROQ_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")

    # –ü—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å
    lines.append(f"\nüí° –ü–†–ò–ì–û–î–ù–û–°–¢–¨")
    active_sources = sum(
        1 for s in report["sources"].values() if s.get("status") == "ok"
    )
    total_events = ai.get("events", 0) if ai.get("status") == "ok" else 0
    lines.append(f"   –ù–æ–≤–æ—Å—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:    {active_sources} –∏–∑ 5")
    lines.append(f"   –°–æ–±—ã—Ç–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:     {total_events}")

    if total_events >= 15:
        quality = "–•–û–†–û–®–û"
    elif total_events >= 5:
        quality = "–°–†–ï–î–ù–ï"
    else:
        quality = "–°–õ–ê–ë–û"
    lines.append(f"   –ö–∞—á–µ—Å—Ç–≤–æ AI-–ø–∞—Ä—Å–∏–Ω–≥–∞:    {quality}")

    if active_sources >= 3 and total_events >= 10:
        rec = "–î–û–°–¢–ê–¢–û–ß–ù–û –î–õ–Ø MVP"
    elif active_sources >= 2:
        rec = "–î–û–ë–ê–í–ò–¢–¨ COINDAR –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã"
    else:
        rec = "–ú–ê–õ–û –ò–°–¢–û–ß–ù–ò–ö–û–í"
    lines.append(f"\n   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {rec}")
    report["verdict"] = rec

    lines.append("\n" + "‚ïê" * 63)
    return "\n".join(lines)


# ---------------------------------------------------------------------------
# –®–∞–≥ 6: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
# ---------------------------------------------------------------------------

def save_reports(report: dict, text_report: str) -> None:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ .txt –∏ .json."""
    os.makedirs(config.REPORTS_DIR, exist_ok=True)
    date_str = report["date"].replace("-", "")

    txt_path = config.REPORTS_DIR / f"news_explore_{date_str}.txt"
    json_path = config.REPORTS_DIR / f"news_explore_{date_str}.json"

    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(text_report)

    # JSON ‚Äî –±–µ–∑ raw_json (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π)
    json_safe = {
        "date": report["date"],
        "sources": {},
        "ai": report.get("ai", {}),
        "verdict": report.get("verdict", ""),
    }
    for key, val in report["sources"].items():
        json_safe["sources"][key] = {
            k: v for k, v in val.items() if k != "raw_json"
        }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_safe, f, ensure_ascii=False, indent=2, default=str)

    print(f"\nüíæ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω:")
    print(f"   {txt_path}")
    print(f"   {json_path}")


# ---------------------------------------------------------------------------
# main
# ---------------------------------------------------------------------------

def main() -> None:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ explore_news.py."""
    print("üöÄ CryptoScanner News & Events Explorer")
    print(f"   –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M')}")

    # –®–∞–≥ 1
    api_status = step_validate()

    # –®–∞–≥ 2
    print("\nüíæ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –ë–î (raw_news + events)...")
    db.init_db()
    print(f"‚úÖ –ë–î –≥–æ—Ç–æ–≤–∞: {config.DB_PATH.name}")

    report: dict = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "sources": {"coindar": {"status": "skip", "count": 0, "note": "–ñ–¥—ë–º –∫–ª—é—á"}},
    }

    # –®–∞–≥ 3A: cryptocurrency.cv
    try:
        explore_cryptocv(report)
    except Exception as e:
        report["sources"]["cryptocv"] = {"status": "error", "count": 0}
        print(f"‚ùå cryptocurrency.cv –æ—à–∏–±–∫–∞: {e}")

    # –®–∞–≥ 3B: CryptoPanic
    if api_status.get("cryptopanic"):
        try:
            explore_cryptopanic(report)
        except Exception as e:
            report["sources"]["cryptopanic"] = {"status": "error", "count": 0}
            print(f"‚ùå CryptoPanic –æ—à–∏–±–∫–∞: {e}")
    else:
        report["sources"]["cryptopanic"] = {"status": "skip", "count": 0}

    # –®–∞–≥ 3C: Binance
    try:
        explore_binance(report)
    except Exception as e:
        report["sources"]["binance"] = {"status": "error", "count": 0}
        print(f"‚ùå Binance –æ—à–∏–±–∫–∞: {e}")

    # –®–∞–≥ 3D: Google News RSS
    try:
        explore_google_news(report)
    except Exception as e:
        report["sources"]["google"] = {"status": "error", "count": 0}
        print(f"‚ùå Google News RSS –æ—à–∏–±–∫–∞: {e}")

    # –®–∞–≥ 4: AI
    if api_status.get("groq"):
        try:
            explore_ai_extraction(report)
        except Exception as e:
            report["ai"] = {"status": "error"}
            print(f"‚ùå AI-–ø–∞—Ä—Å–∏–Ω–≥ –æ—à–∏–±–∫–∞: {e}")
    else:
        report["ai"] = {"status": "skip"}

    # –®–∞–≥ 5: –°–≤–æ–¥–∫–∞
    text_report = build_summary(report)
    print(text_report)

    # –®–∞–≥ 6: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    save_reports(report, text_report)

    print("\n‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n‚õî –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
